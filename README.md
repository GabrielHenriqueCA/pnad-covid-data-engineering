# üè• Tech Challenge - PNAD COVID-19 | Data Engineering & Analytics

![AWS](https://img.shields.io/badge/AWS-S3%20%7C%20Glue%20%7C%20Athena-FF9900?style=for-the-badge&logo=amazonaws&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-4.0.0-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)
![Parquet](https://img.shields.io/badge/Format-Parquet-50ABF1?style=for-the-badge&logo=apache&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-Dashboard-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)
![Status](https://img.shields.io/badge/Status-Complete-00C853?style=for-the-badge)

## üìã About the Project

This project is part of the **Tech Challenge - Phase 3** of the Post-Graduate program, where I implemented a complete **Data Engineering** solution to analyze **PNAD COVID-19 (IBGE)** data, providing strategic intelligence for hospital decision-making.

### üéØ Business Problem

A large hospital needed to understand Brazilian population behavior during the COVID-19 pandemic (Sep/Oct/Nov 2020) to:
- **Plan bed allocation** based on positivity rates
- **Identify risk groups** (comorbidities, age group, race)
- **Optimize testing** by analyzing predictor symptoms
- **Understand socioeconomic impacts** (remote work, emergency aid)

### üí° Implemented Solution

Cloud-based **ELT pipeline** with **AWS Glue** (PySpark) processing **340+ MB of raw data** through **Medallion Architecture** (Bronze ‚Üí Silver ‚Üí Gold), resulting in **optimized analytical data** for Power BI queries.

---

## üèóÔ∏è Data Architecture (Medallion Architecture)

![Architecture](images/architecture_diagram.png)

```mermaid
graph TB
    A[IBGE - CSVs<br/>344 MB] -->|Manual Upload| B[S3 Raw Zone<br/>Parquet + Snappy]
    B -->|PySpark ETL| C{AWS Glue Notebook}
    C -->|Bronze<br/>Unification| D[(tb_pnad_covid_bronze<br/>3 months unified)]
    D -->|Silver<br/>Translation| E[(tb_pnad_covid_silver<br/>Codes ‚Üí Text)]
    E -->|Gold<br/>Business Logic| F[(tb_pnad_covid_gold<br/>~70 MB Parquet)]
    F -->|SQL Queries| G[AWS Athena<br/>15 Questions]
    G -->|BI Connector| H[Power BI]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#ffe1f5
    style D fill:#ffd4d4
    style E fill:#d4d4ff
    style F fill:#c1f0c1
    style G fill:#ffe1f5
    style H fill:#f0e1ff
```

### üîß Technology Stack

| Layer | Technology | Function |
|--------|-----------|--------|
| **Storage** | AWS S3 | Data Lake (raw + processed zones) |
| **Processing** | AWS Glue (PySpark 4.0.0) | ETL Bronze ‚Üí Silver ‚Üí Gold |
| **Query Engine** | AWS Athena (Presto SQL) | Ad-hoc analytics |
| **Format** | Apache Parquet + Snappy | Compressed columnar storage |
| **Visualization** | Power BI | Executive dashboards |

---

## ‚ö° Data Pipeline (3 Layers)

### ü•â Bronze Layer (Raw Data)
**File**: `code/PNAD_Covid.ipynb` (cells 1-11)

```python
# Unifying 3 months of data
micro_unificado = reduce(
    lambda df1, df2: df1.unionByName(df2, allowMissingColumns=True),
    [micro_09, micro_10, micro_11]
)
# Result: 148 completely raw columns
```

**Outputs**:
- `s3://your-pnad-bucket/data-output/pnad_covid_bronze/` (Parquet + Snappy)
- **Glue Table**: `workspace.tb_pnad_covid_bronze`

---

### ü•à Silver Layer (Data Quality)
**File**: `code/PNAD_Covid.ipynb` (cells 12-16)

#### Applied Transformations:

1. **Code Translation** (using IBGE dictionary):
```python
# Example: B009B (code "1") ‚Üí "Positive"
for var, dim in dims.items():
    mapping = create_mapping(dim)
    micro_traduzido = apply_translation(micro_traduzido, var, mapping)
```

2. **Smart Column Renaming**:
```python
# B009B ‚Üí "qual_o_resultado_2"
# A003  ‚Üí "sexo"
# A004  ‚Üí "cor_ou_raca"
```

**Result**: Human-readable data, ready for analysis.

---

### ü•á Gold Layer (Business Metrics)
**File**: `sql/04_business_metrics.sql` (conceptual example - actual processing in Glue)

Final table optimized to answer **15 key business questions**:

```sql
CREATE TABLE workspace.tb_pnad_covid_gold AS
SELECT 
    id,
    mes_da_pesquisa,
    unidade_da_federacao,
    sexo,
    idade_do_morador,
    cor_ou_raca,
    escolaridade,
    
    -- COVID Symptoms (13 columns)
    na_semana_passada_teve_febre,
    na_semana_passada_teve_tosse,
    na_semana_passada_teve_perda_de_cheiro_ou_sabor,
    
    -- Test Results (3 types)
    qual_o_resultado AS qual_o_resultado,        -- SWAB
    qual_o_resultado_2 AS qual_o_resultado_2,    -- Rapid (finger)
    qual_o_resultado_3 AS qual_o_resultado_3,    -- Serology (vein)
    
    -- Work and Economy
    na_semana_passada_o_a_sr_a_estava_em_trabalho_remoto_home_office_ou_teletrabalho,
    auxilios_emergenciais_relacionados_ao_coronavirus,
    
    ... -- 148+ total columns
FROM tb_pnad_covid_silver
```

**Optimizations**:
- ‚úÖ **Snappy** compression (79% reduction vs CSV)
- ‚úÖ **Columnar** format (selective scan)
- ‚úÖ **Normalized** and **typed** data

---

## üìä Data Analysis (15 Key Questions)

**File**: `athena/business_queries.sql` ‚Üí Real Athena queries

### Questions Answered

| # | Business Question | Athena Query | Expected Insight |
|---|---------------------|--------------|------------------|
| **Q1** | Difference in positivity rate between men and women? | `SELECT sexo, taxa_percentual...` | Identify most vulnerable gender |
| **Q2** | Age group with highest positive rate? | `SELECT faixa_etaria, taxa_percentual...` | Prioritize protection by age |
| **Q3** | Racial inequality in testing and positivity? | `SELECT cor_ou_raca, taxa_acesso, taxa_positividade...` | Evidence structural inequality |
| **Q4** | Does education influence chance of testing positive? | `SELECT escolaridade, taxa_positividade...` | Correlate education with risk |
| **Q5** | Which symptoms are most frequent in positives? | `SELECT sintoma, COUNT()...` | Symptom ranking |
| **Q6** | Is loss of smell/taste the best predictor? | `SELECT sintoma, chance_de_ser_covid...` | Identify key symptom |
| **Q7** | Proportion of asymptomatic among infected? | `SELECT quadro_clinico, porcentagem...` | Plan preventive testing |
| **Q8** | Do remote workers have lower infection rate? | `SELECT fez_home_office, taxa_positividade...` | Evaluate distancing effectiveness |
| **Q9** | Difference between capitals and interior? | `SELECT capital, taxa_positividade...` | Compare regional profiles |
| **Q10** | Which test type had highest positive rate? | `SELECT tipo_teste, taxa_positividade...` | Evaluate test sensitivity |
| **Q11** | Does health plan influence testing? | `SELECT possui_plano, taxa_acesso_exame...` | Measure access inequality |
| **Q12** | Did those seeking care have higher rate? | `SELECT buscou_atendimento, taxa_positividade...` | Evaluate care effectiveness |
| **Q13** | Regional difference (state) in infection rate? | `SELECT uf, taxa_positividade...` | Heat map by state |
| **Q14** | Did remote workers show lower rate? | (Duplicate of Q8) | - |
| **Q15** | Is emergency aid associated with higher infection? | `SELECT recebeu_auxilio, taxa_positividade...` | Correlate social vulnerability |

---

## üìÅ Repository Structure

```
TC3/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md                          # Main documentation (you are here!)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ code/                              # Processing Pipeline
‚îÇ   ‚îî‚îÄ‚îÄ PNAD_Covid.ipynb                 # AWS Glue Notebook (PySpark)
‚îÇ                                        # Bronze ‚Üí Silver ‚Üí Gold
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/                              # Raw Data (CSV - 344 MB)
‚îÇ   ‚îú‚îÄ‚îÄ PNAD_COVID_092020.csv            # September (117 MB, 384k rows)
‚îÇ   ‚îú‚îÄ‚îÄ PNAD_COVID_102020.csv            # October (113 MB, 368k rows)
‚îÇ   ‚îú‚îÄ‚îÄ PNAD_COVID_112020.csv            # November (114 MB, 361k rows)
‚îÇ   ‚îî‚îÄ‚îÄ Dicionario_PNAD_COVID_*.csv      # IBGE metadata
‚îÇ
‚îú‚îÄ‚îÄ üìÇ athena/                            # Analytical Queries
‚îÇ   ‚îî‚îÄ‚îÄ business_queries.sql             # 15 real business questions
‚îÇ
‚îú‚îÄ‚îÄ üìÇ sql/                               # Conceptual SQL Scripts
‚îÇ   ‚îú‚îÄ‚îÄ 01_create_raw_table.sql          # Bronze DDL (conceptual)
‚îÇ   ‚îú‚îÄ‚îÄ 02_create_processed_parquet.sql  # Silver DDL + Parquet
‚îÇ   ‚îú‚îÄ‚îÄ 03_data_quality_transforms.sql   # Cleaning transformations
‚îÇ   ‚îî‚îÄ‚îÄ 04_business_metrics.sql          # Gold table
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/                              # Technical Documentation
‚îÇ   ‚îú‚îÄ‚îÄ data_dictionary.md               # Complete dictionary (148 columns)
‚îÇ   ‚îú‚îÄ‚îÄ business_requirements.md         # Hospital requirements
‚îÇ   ‚îî‚îÄ‚îÄ useful_commands.md               # AWS CLI, PySpark, troubleshooting
‚îÇ
‚îú‚îÄ‚îÄ üìÇ images/                            # Visual Resources
‚îÇ   ‚îî‚îÄ‚îÄ architecture_diagram.png         # Architecture diagram
‚îÇ
‚îÇ
‚îî‚îÄ‚îÄ üìÑ .gitignore                         # Sensitive data protection
```

---

## üöÄ How to Reproduce

### Prerequisites
- ‚úÖ Active AWS account
- ‚úÖ Permissions: **S3**, **Glue**, **Athena**, **IAM**
- ‚úÖ Power BI Desktop (optional, for dashboards)
- ‚úÖ Python 3.10+ with PySpark 4.0.0

---

### Step by Step

#### 1Ô∏è‚É£ Upload Data to S3 (Manual)
```bash
# Create S3 bucket
aws s3 mb s3://your-pnad-bucket --region sa-east-1

# Upload CSVs
aws s3 sync data/ s3://your-pnad-bucket/data-input/microdados/ \
  --exclude "*" --include "*.csv"

# Verify upload
aws s3 ls s3://your-pnad-bucket/data-input/microdados/ --recursive --human-readable
```

---

#### 2Ô∏è‚É£ Process Data with AWS Glue (PySpark)

**Option A: Glue Studio Notebook** (recommended)
1. Open **AWS Glue** ‚Üí **Notebooks**
2. Create new notebook with **IAM role** with S3 permissions
3. Upload `code/PNAD_Covid.ipynb`
4. Execute cell by cell (**~15 min** processing)

**Option B: Glue Job (automated)**
```bash
# Create Glue job via CLI
aws glue create-job \
  --name pnad-covid-etl \
  --role AWSGlueServiceRole \
  --command "Name=glueetl,ScriptLocation=s3://your-pnad-bucket/scripts/PNAD_Covid.py" \
  --default-arguments '{
    "--job-language":"python",
    "--spark-version":"4.0"
  }'

# Execute job
aws glue start-job-run --job-name pnad-covid-etl
```

**Expected Outputs**:
```
s3://your-pnad-bucket/data-output/
‚îú‚îÄ‚îÄ pnad_covid_bronze/    (Parquet ~344 MB)
‚îú‚îÄ‚îÄ pnad_covid_silver/    (Parquet ~150 MB)
‚îî‚îÄ‚îÄ pnad_covid_gold/      (Parquet ~70 MB) ‚≠ê
```

---

#### 3Ô∏è‚É£ Create Tables in Athena (Crawler or DDL)

**Option A: AWS Glue Crawler (automatic)**
```bash
aws glue create-crawler \
  --name pnad-covid-crawler \
  --role AWSGlueServiceRole \
  --database-name pnad_covid \
  --targets "S3Targets=[{Path=s3://your-pnad-bucket/data-output/}]"

aws glue start-crawler --name pnad-covid-crawler
```

**Option B: Manual DDL in Athena**
```sql
-- Create database
CREATE DATABASE IF NOT EXISTS pnad_covid;

-- Create Gold table
CREATE EXTERNAL TABLE pnad_covid.tb_pnad_covid_gold(
  id BIGINT,
  ano_de_referencia INT,
  mes_da_pesquisa INT,
  unidade_da_federacao STRING,
  sexo STRING,
  idade_do_morador INT,
  cor_ou_raca STRING,
  escolaridade STRING,
  qual_o_resultado STRING,
  qual_o_resultado_2 STRING,
  qual_o_resultado_3 STRING,
  -- ... (148 total columns)
)
STORED AS PARQUET
LOCATION 's3://your-pnad-bucket/data-output/pnad_covid_gold/'
```

---

#### 4Ô∏è‚É£ Execute Analytical Queries (Athena)

Copy queries from file **`athena/business_queries.sql`** and execute in **Athena Console**:

```sql
-- Example: Question 1 (Positivity rate by gender)
SELECT 
    CASE 
        WHEN mes_da_pesquisa = 9 THEN 'September'
        WHEN mes_da_pesquisa = 10 THEN 'October'
        WHEN mes_da_pesquisa = 11 THEN 'November'
    END AS month,
    sexo,
    -- Rate %
    ROUND(
        100.0 * SUM(CASE 
            WHEN qual_o_resultado = 'Positivo' 
              OR qual_o_resultado_2 = 'Positivo' 
              OR qual_o_resultado_3 = 'Positivo' 
            THEN 1 ELSE 0 END) 
        / 
        NULLIF(SUM(CASE 
            WHEN qual_o_resultado IN ('Positivo', 'Negativo') 
              OR qual_o_resultado_2 IN ('Positivo', 'Negativo') 
              OR qual_o_resultado_3 IN ('Positivo', 'Negativo') 
            THEN 1 ELSE 0 END), 0)
    , 1) AS positivity_rate_pct,
    
    SUM(CASE 
        WHEN qual_o_resultado = 'Positivo' 
          OR qual_o_resultado_2 = 'Positivo' 
          OR qual_o_resultado_3 = 'Positivo' 
        THEN 1 ELSE 0 END) AS total_positives,
    
    SUM(CASE 
        WHEN qual_o_resultado IN ('Positivo', 'Negativo') 
          OR qual_o_resultado_2 IN ('Positivo', 'Negativo') 
          OR qual_o_resultado_3 IN ('Positivo', 'Negativo') 
        THEN 1 ELSE 0 END) AS total_tested

FROM tb_pnad_covid_gold
WHERE sexo IS NOT NULL 
  AND mes_da_pesquisa IN (9, 10, 11)
GROUP BY mes_da_pesquisa, sexo
ORDER BY mes_da_pesquisa, sexo;
```

**Estimated cost**: $0.0035 per query (70 MB scanned)

---

#### 5Ô∏è‚É£ Connect Power BI (optional)

1. **Install driver**: [Amazon Athena ODBC Driver](https://docs.aws.amazon.com/athena/latest/ug/connect-with-odbc.html)
2. **Configure connection in Power BI**:
   - Server: `athena.sa-east-1.amazonaws.com`
   - Database: `pnad_covid`
   - S3 Output Location: `s3://your-pnad-bucket/athena-results/`
   - Authentication: **IAM Credentials**
3. **Import table** `tb_pnad_covid_gold`
4. **Create visualizations** based on the 15 questions

---

## üìà Results and Impact

### Performance Comparison: CSV vs. Parquet

| Metric | CSV (Original Format) | Parquet + Snappy (Optimized) | Gain |
|---------|------------------------|------------------------------|-------|
| **Total Size** | 344 MB (3 files) | ~70 MB (unified) | **79% smaller** |
| **Query Time** | ~45 seconds (full scan) | ~8 seconds (selected columns) | **5.6x faster** |
| **Cost per Query** | $0.0172 (344 MB @ $5/TB) | $0.0035 (70 MB @ $5/TB) | **80% cheaper** |
| **Data Scanned** | 344 MB (all columns) | ~50 MB (only necessary) | **85% reduction** |

> üí∞ **Estimated annual savings**: For 10,000 queries/year, savings of **~$137** (from $172 to $35)

### Key Generated Insights

‚úÖ **Predictor Symptoms**: Loss of smell/taste as best COVID-19 indicator  
‚úÖ **Racial Inequality**: Significant differences in test access between racial groups  
‚úÖ **Risk Ranges**: Identification of age groups with highest positivity rate  
‚úÖ **Remote Work**: Evidence of infection reduction in remote workers  
‚úÖ **Economic Impact**: Correlation between emergency aid and social vulnerability  

---

## üß† Technical Decisions

### Why Medallion Architecture?

| Layer | Purpose | Benefit |
|--------|-----------|-----------|
| **Bronze** | Immutable raw data | Audit and reprocessing |
| **Silver** | Clean and structured data | Quality and consistency |
| **Gold** | Business metrics | Query performance |

### Why Glue instead of EMR/Databricks?

- ‚úÖ **Serverless**: No cluster management
- ‚úÖ **Native integration** with S3 and Athena
- ‚úÖ **Cost-effective** for batch workloads
- ‚úÖ **Interactive notebooks** for development

### Why Parquet + Snappy?

- **Parquet**: Columnar format ‚Üí selective scan (reads only necessary columns)
- **Snappy**: Decompression speed 2-3x faster than GZIP
- **Cost-benefit**: ~60% of GZIP size, but much faster queries

---

## üë®‚Äçüíª Author

**Gabriel Henrique** - Data Engineer  
üéì Data Engineering Post-Graduate Student | FIAP  
üíº Specialized in **Modern Data Architectures** on AWS (S3, Glue, Athena, Redshift, PySpark)  
üöÄ Experience with ELT pipelines, Medallion Architecture, and performance optimization

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/gabrielhenri/)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/gabrielhenrique-eng)
[![Email](https://img.shields.io/badge/Email-Contact-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:gabrielhcacontato@gmail.com)

> üí° **Open to opportunities** in Data Engineering, Analytics Engineering and Cloud Data Platforms

---

## üìù License

This project is part of academic work (**Tech Challenge - FIAP Post-Graduate Program**).  
Public data provided by **IBGE** (PNAD COVID-19).

---

## üôè Acknowledgments

- **IBGE** for providing PNAD COVID-19 microdata
- **FIAP** for the practical challenge-oriented learning environment
- **AWS** for complete documentation and powerful Data Engineering tools

---

<div align="center">

**‚≠ê If this project was useful, consider giving it a star on the repository!**

**Developed with** ‚ù§Ô∏è **using AWS Glue, PySpark, Athena and Power BI**

</div>
